---
title: "Hierarchical Edge Bundles in R"
date: `r Sys.Date()`
time: "20:00"
excerpt: "Introduction to an R implementation of Hierarchical Edge Bundles"
author: "Anders Ellern Bilgrau"
draft: false
toc: true
tags:
  - hierachical clustering
  - graphs
  - visualisation
images:
  - /network2.jpg
output: 
  html_document: 
    keep_md: yes
    number_sections: yes
    toc: yes
---

```{r setup, echo = FALSE}
set.seed(754625961)
library("kableExtra")
options(kableExtra.html.bsTable = TRUE)
```

{{< figure src="/images/network2.jpg" alt="image" caption="Hierarchical edge bundling of a gene network. Blue indicate negative correlations, red indicate positive. The darker the color, the more strong the correlation." class="big" >}}

## Background

During the finalization of my PhD, I implemented the so-called *Hierarchical Edge Bundling* plotting method for a paper now [published in the Annals of Applied Statistics](https://projecteuclid.org/euclid.aoas/1536652979). 
Though the plot above sadly did not make the final cut, I admit due to an lack of added value, it appeared in the original submission and the thesis. 
Suffice it to say, I was still quite pleased with the method at the time, so I wrapped the methods into an **R**-package called [**HierachicalEdgeBundles**](https://github.com/AEBilgrau/HierarchicalEdgeBundles). 
The plan was then to do a very small paper on this topic but I never got around to it.

The plot above illustrates estimated correlations of selected genes within the disease called diffuse large B-cell lymphoma the method.


## What is hierarchical edge bundling?

Hierarchical edge bundling is a visualization technique for displaying the relations in a network that additionally submit to some hierarchical structure.
The method was originally suggested in 2006 in a [lovely paper by Danny Holten](https://ieeexplore.ieee.org/document/4015425).
In short, hierarchical edge bundling visualizes graphs (of nodes and edges) by guiding the edges along along a hierarchical tree of the nodes.
A bundling parameter then controls how tightly the edges follow this underlying tree. 
So what data fits into this technique?

### The data 

The typical data suitable for this visualization needs two basic properties:

1. The data can be represented as a graph (directed or undirected)
2. The data can be arranged hierarchically 

If the data does not adhere to one of these properties the lacking properties may often be constructed. 
Now, I say 'data' here. But by 'data' I mean the likely processed data that goes in to the plotting method, not necessarily the *collected* data. 

Let me illustrate by using the **R** package.


## Using the **HierarchicalEdgeBundles** package

### Installation

First things first. To install the package directly from the [repository on GitHub](https://github.com/AEBilgrau/HierarchicalEdgeBundles), we run:

```{r package_installation, eval=FALSE}
#install.packages("remotes")  # Uncomment if devtools is not installed
remotes::install_github("AEBilgrau/HierarchicalEdgeBundles")
```


### Toy data

To illustrate the package use, we use a typical go-to dataset in **R**. 
The `mtcars` dataset:

```{r mtcars_show, eval=FALSE}
data(mtcars)
head(mtcars, n = 10)
```
```{r mtcars_pretty_print, results='asis', echo = FALSE}
head(mtcars, n = 10) %>% 
   kable(format = "markdown", align = "c")  # Pretty printing
```

The `mtcars` contains data for various specs of 32 cars where only the `n = 10` first cars are shown above. 
Suppose that we would like to examine the 'closeness' of these cars to each other.
So it is natural to evaluate all pairs of cars by some metric. 
Using `dist` and its default euclidean metric, say, to compute the distance matrix we get:


```{r car_dist}
car_dist <- dist(mtcars) # Compute pairwise distances 

# Show first four rows and columns 
round(as.matrix(car_dist)[1:4, 1:4], 1)
```

These distances are measures of 'dissimilarity' between the cars. 
Greater value corresponds to a greater dissimilarity of the cars.
We do not bother here to consider if the euclidean metrics is a well-suited measure for this (it is likely not).
Nonetheless, since `car_dist` is a symmetric matrix it can be represented by a complete weighted graph. Using the `igraph` package, we can display it as such easily:

```{r car_dist_plot, message=FALSE, echo = c(1:4, 15)}
library("igraph")

car_graph <- graph_from_adjacency_matrix(
  log(1/as.matrix(car_dist)), mode = "undirected", weighted = TRUE, diag = FALSE
)

# Function for mapping values linearly to [0, 1]
rescale <- function(x) {  
  return((x - min(x))/max(x - min(x)))
}

# Tweaks for some pretty plotting 
E(car_graph)$width <- 4*rescale(E(car_graph)$weight)
E(car_graph)$color <- hsv(h = 0.02, s = 0.6, alpha = rescale(E(car_graph)$weight))
V(car_graph)$size <- 10
V(car_graph)$color <- "steelblue"

par(mar = c(0, 0, 0, 0))

plot(car_graph, layout = layout_with_fr(car_graph, weights = E(car_graph)$weight))
```

**Note** that I `log(1/dist)` as *similarity* --- graph layout algorithms assume 

The first of our two ingredients.

Using the  dissimilarities we can, for example, use regular hierarchical clustering to arrive a the second ingredient:

```{r hclust_plot}
car_hc <- hclust(car_dist, "ave")
plot(car_hc)
```

A tree.

We happily notice that similar cars indeed cluster together: Merc 450's are closely connected; as are some automakers such as Fiat and Mazda. 



```{r final_plot, plots}
library("HierarchicalEdgeBundles")
library("igraph")
library("ape")

graph <- watts.strogatz.game(1, size = 10, nei = 2, p = 0.5)
adj.mat <- get.adjacency(graph)
phylo <- as.phylo(hclust(as.dist(1-adj.mat)))

plot(graph, layout = layout_in_circle(graph))
plotHEB(graph, phylo, type = "fan")
```



## References

* Danny Holten (2006) [**"Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data"**](https://ieeexplore.ieee.org/document/4015425), IEEE Transactions on Visualization and Computer Graphics, 12 (5): 741-748.

