---
title: "Hierarchical Edge Bundles in R"
date: `r Sys.Date()`
time: "20:00"
excerpt: "Introduction to an R implementation of Hierarchical Edge Bundles"
author: "Anders Ellern Bilgrau"
draft: false
toc: true
tags:
  - hierachical clustering
  - graphs
  - visualisation
images:
  - /network2.jpg
output: 
  html_document: 
    keep_md: yes
    number_sections: yes
    toc: yes
---

```{r setup, echo = FALSE}
set.seed(754625961)
library("kableExtra")
options(kableExtra.html.bsTable = TRUE)
```

{{< figure src="/images/network2.jpg" alt="image" caption="Hierarchical edge bundling of a gene network. Blue indicate negative correlations, red indicate positive. The darker the color, the more strong the correlation." class="big" >}}

## Background

During the finalization of my PhD, I implemented the so-called *Hierarchical Edge Bundling* plotting method for a paper now [published in the Annals of Applied Statistics](https://projecteuclid.org/euclid.aoas/1536652979). 
Though the plot above sadly did not make the final cut, I admit due to an lack of added value, it appeared in the original submission and the thesis. 
Suffice it to say, I was still quite pleased with the method at the time, so I wrapped the methods into an **R**-package called [**HierachicalEdgeBundles**](https://github.com/AEBilgrau/HierarchicalEdgeBundles). 
The plan was then to do a very small paper on this topic but I never got around to it.

The plot above illustrates estimated correlations of selected genes within the disease called diffuse large B-cell lymphoma the method.


## What is hierarchical edge bundling?

Hierarchical edge bundling is a visualization technique for displaying the relations in a network that additionally submit to some hierarchical structure.
The method was originally suggested in 2006 in a [lovely paper by Danny Holten](https://ieeexplore.ieee.org/document/4015425).
In short, hierarchical edge bundling visualizes graphs (of nodes and edges) by guiding the edges along along a hierarchical tree of the nodes.
A bundling parameter then controls how tightly the edges follow this underlying tree. 
So what data fits into this technique?

### The data 

The typical data suitable for this visualization needs two basic properties:

1. The data can be represented as a graph (directed or undirected)
2. The data can be arranged hierarchically 

If the data does not adhere to one of these properties the lacking properties may often be constructed. 
Now, I say 'data' here. But by 'data' I mean the likely processed data that goes in to the plotting method, not necessarily the *collected* data. 

Let me illustrate by using the **R** package.


## Using the **HierarchicalEdgeBundles** package

### Installation

First things first. To install the package directly from the [repository on GitHub](https://github.com/AEBilgrau/HierarchicalEdgeBundles), we run:

```{r package_installation, eval=FALSE}
#install.packages("remotes")  # Uncomment if devtools is not installed
remotes::install_github("AEBilgrau/HierarchicalEdgeBundles")
```

```{r package_loads}
library("HierarchicalEdgeBundles")
library("ape")
library("igraph")
```

### Toy data

To illustrate the package use, we use a typical go-to dataset in **R**. 
The `mtcars` dataset:

```{r mtcars_show, eval=FALSE}
data(mtcars)
head(mtcars, n = 10)
```
```{r mtcars_pretty_print, results='asis', echo = FALSE}
head(mtcars, n = 10) %>% 
   kable(format = "markdown", align = "c")  # Pretty printing
```

The `mtcars` contains data for various specs of 32 cars where only the `n = 10` first cars are shown above. 
Suppose that we would like to examine the 'closeness' of these cars to each other.
So it is natural to evaluate all pairs of cars by some metric. 
Using `dist` and its default euclidean metric, say, to compute the distance matrix we get:


```{r car_dist}
car_cor <- cor(mtcars)
# Show first six rows and columns 
round(as.matrix(car_cor)[1:6, 1:6], 1)


# car_dist <- dist(mtcars) # Compute pairwise distances 
car_dist <- as.dist((1 - car_cor)/2)

# Show first four rows and columns 
round(car_dist, 1)
```

These distances are measures of 'dissimilarity' between the car features. 
Greater value corresponds to a greater dissimilarity of the features.
We do not bother here to consider if the euclidean metrics is a well-suited measure for this (it is likely not).
Nonetheless, since `car_dist` is a symmetric matrix it can be represented by a complete weighted graph. Using the `igraph` package, we can display it as such easily:

```{r car_dist_plot, message=FALSE, echo = c(1:4, 15)}
library("igraph")

car_graph <- graph_from_adjacency_matrix(
  car_cor,
  # log(1/as.matrix(car_dist)), 
  mode = "undirected", weighted = TRUE, diag = FALSE
)

# Function for mapping values linearly to [0, 1]
rescale <- function(x) {  
  # return((x - min(x))/max(x - min(x)))
  return((x + 1)/2)
}

# Tweaks for some pretty plotting 
cr <- colorRamp(c("seagreen", "white", "tomato"), space = "Lab")
v <- cr(rescale(E(car_graph)$weight))
E(car_graph)$width <- 4*rescale(E(car_graph)$weight)
E(car_graph)$color <- rgb(v[,1], v[,2], v[, 3], maxColorValue = 255)
V(car_graph)$label.color <- "black"
V(car_graph)$size <- 8
V(car_graph)$color <- "white"

par(mar = c(0, 0, 0, 0))
plot(car_graph, layout = layout_in_circle(car_graph))
```

**Note** that I `log(1/dist)` as *similarity* --- graph layout algorithms assume 

The first of our two ingredients.

Using the  dissimilarities we can, for example, use regular hierarchical clustering to arrive a the second ingredient:


```{r hclust_plot}
car_hc <- as.phylo(hclust(car_dist, "ave"))
plot(car_hc)
```

A tree.

We happily notice that features which a priori are connected indeed also are (strongly) correlated and cluster together; e.g. the number of *cyl*inders and *disp*lacement. 

Notice that I've wrapped the tree from `hclust` in `as.phylo` from the **ape** package to convert it as needed later. The reason is that the plotting uses the internal nodes of the tree and those are (or at least were) not available in the tree object from `hclust`.


```{r bundling}
car_phylo <-

par(mar = c(0,0,0,0))
plotHEB(car_graph, car_phylo, beta = 0.8, type = "fan",
        e.cols = E(car_graph)$color, args.lines = list(lwd = 2))
```

Or with a little less bundling and as the phyologram and the internal nodes of the underlying tree plotted as well:

```{r alt_bundle}
par(mar = c(0,0,0,0))
plotHEB(car_graph, car_phylo, beta = 0.7, type = "cladogram",
        e.cols = E(car_graph)$color, args.lines = list(lwd = 2))
```

As can be noted in the documentation of the package, it is `plot.phylo` from **`ape`** that controls much of the plotting. This also explain the excessive white space with this layout as the entire tree would normally be drawn.




## References

* Danny Holten (2006) [**"Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data"**](https://ieeexplore.ieee.org/document/4015425), IEEE Transactions on Visualization and Computer Graphics, 12 (5): 741-748.

